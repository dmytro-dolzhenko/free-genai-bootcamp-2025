# DeepSeek Powered Assistant Guide

## Which model

DeepSeek R1 Distill Llama 8B 

> Model was running locally in LM Studio software. Model was downloaded from [Hugging Face](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B)

> LM studio allows to configure the model. Mode was tested with different Context Length, specifically 4096 and 8192 tokens.

# Prompting Guide

No official guide.

https://www.kaggle.com/code/lonnieqin/prompt-engineering-with-deepseek-chat
